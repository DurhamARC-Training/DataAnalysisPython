{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap of Basic Python features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    " Copyright (c) 2024 Paul Niklas RUth\n",
    " \n",
    " This Source Code Form is subject to the terms of the Mozilla Public\n",
    " License, v. 2.0. If a copy of the MPL was not distributed with this\n",
    " file, You can obtain one at https://mozilla.org/MPL/2.0/.\n",
    "-->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can add functionality to python by importing modules\n",
    "\n",
    "Some of the modules come with\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionaries are like a labelled drawer containing arbitrary data\n",
    "Data is accessed by keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Dictionaries are like a labelled drawer containing arbitrary data\n",
      "Data is accessed by keyword\n"
     ]
    }
   ],
   "source": [
    "my_dict = {'name': 'John', 1: [2, 4, 3]}\n",
    "print(\"my_dict['name']:\", my_dict['name'])\n",
    "print(\"my_dict[1]:\", my_dict[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Pandas and Data Loading\n",
    "\n",
    "Pandas is a powerful Python library for data manipulation and analysis.\n",
    "\n",
    "Speaker Notes:\n",
    "- Pandas is widely used in data science and is built on top of NumPy.\n",
    "- It provides data structures like Series and DataFrame for handling structured data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started with Pandas\n",
    "\n",
    "To begin, we need to import the pandas library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speaker Notes:\n",
    "\n",
    " - We import pandas using the alias pd for convenience.\n",
    " - This allows us to refer to pandas functions and objects using the shorthand pd."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data with Pandas\n",
    "\n",
    "Pandas provides various functions for loading data into DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/DAC_Study_4_PS.sav.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speaker Notes:\n",
    "\n",
    " - Here, we use the `read_csv()` function to load data from a CSV file into a DataFrame.\n",
    " - The data is stored in the variable data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to the Dataset\n",
    "\n",
    "The dataset used in this tutorial is lifted from a study conducted by Gino & Wiltermuth (2014) titled \"Evil Genius? How Dishonesty Can Lead to Greater Creativity\", published in Psychological Science. The study investigates the relationship between dishonesty and creativity.\n",
    "\n",
    "#### Dataset Source:\n",
    "[Link to the discussion we are reproducing](https://datacolada.org/110)\n",
    "\n",
    "#### Description:\n",
    "The dataset contains responses from participants who were presented with a virtual coin toss task followed by a creativity task involving generating uses for a newspaper. The study examines whether participants who cheated on the coin toss task exhibited greater creativity in the subsequent task compared to non-cheaters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Speaker Notes:\n",
    "- The dataset used in this tutorial is sourced from a study by Gino & Wiltermuth (2014) on dishonesty and creativity.\n",
    "- Participants were first engaged in a coin toss task and then asked to generate creative uses for a newspaper.\n",
    "- The dataset allows us to explore the relationship between dishonesty and creativity as measured by the number of creative uses generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Data\n",
    "\n",
    "Once we have loaded the data, we can explore its structure and contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0            StartDate              EndDate  Cum_ID  filter  \\\n",
      "0           1  2012-11-17 23:54:00  2012-11-18 00:07:12     144       5   \n",
      "1           2  2012-11-17 23:17:26  2012-11-17 23:41:13      91       5   \n",
      "2           3  2012-11-17 23:44:36  2012-11-17 23:57:53     127       5   \n",
      "3           4  2012-11-17 22:57:36  2012-11-17 23:11:29      24       5   \n",
      "4           5  2012-11-18 00:00:06  2012-11-18 00:20:19     168       5   \n",
      "\n",
      "   filter2  CF_headsheads1tails2  num_coin_tosses  instr  \\\n",
      "0        1                     1                3      1   \n",
      "1        1                     1                3      1   \n",
      "2        1                     2                3      1   \n",
      "3        1                     2                3      1   \n",
      "4        1                     1                3      1   \n",
      "\n",
      "   reported_guessed_correctly  ...  ethnicity_5  ethnicity_6  student  code  \\\n",
      "0                           0  ...          NaN          1.0      1.0     1   \n",
      "1                           0  ...          NaN          1.0      0.0     1   \n",
      "2                           0  ...          NaN          1.0      1.0     1   \n",
      "3                           0  ...          NaN          1.0      0.0     1   \n",
      "4                           0  ...          NaN          NaN      0.0     1   \n",
      "\n",
      "   care_about_rules  pos_affect  neg_affect  RAT_perf  cheated  \\\n",
      "0          6.000000         2.3         2.5         9        0   \n",
      "1          5.333333         2.5         1.4         8        0   \n",
      "2          6.000000         2.1         1.1         9        0   \n",
      "3          6.333333         1.3         1.0        12        0   \n",
      "4          5.333333         2.8         1.3         0        0   \n",
      "\n",
      "                        MTurkID_md5  \n",
      "0  165d039a661a10e307754efba79a6110  \n",
      "1  7ff5028e3f50f083999a7e904694524d  \n",
      "2  0795454a621e15bff1b89c8a14efa41e  \n",
      "3  c55d3da1c3ab1bcba89145f8bcb5a75e  \n",
      "4  ad13ddfad7d7753a38595810fdaa566a  \n",
      "\n",
      "[5 rows x 79 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the DataFrame\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speaker Notes:\n",
    "\n",
    " - The head() function displays the first few rows of the DataFrame.\n",
    " - This allows us to quickly inspect the data and get an idea of its format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Data\n",
    "We can also get information about the DataFrame using the `info()` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 178 entries, 0 to 177\n",
      "Data columns (total 79 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Unnamed: 0                  178 non-null    int64  \n",
      " 1   StartDate                   178 non-null    object \n",
      " 2   EndDate                     178 non-null    object \n",
      " 3   Cum_ID                      178 non-null    int64  \n",
      " 4   filter                      178 non-null    int64  \n",
      " 5   filter2                     178 non-null    int64  \n",
      " 6   CF_headsheads1tails2        178 non-null    int64  \n",
      " 7   num_coin_tosses             178 non-null    int64  \n",
      " 8   instr                       178 non-null    int64  \n",
      " 9   reported_guessed_correctly  178 non-null    int64  \n",
      " 10  ruleFollow1                 178 non-null    int64  \n",
      " 11  ruleFollow2                 178 non-null    int64  \n",
      " 12  ruleFollow3                 178 non-null    int64  \n",
      " 13  Numberofresponses           178 non-null    int64  \n",
      " 14  Originality                 178 non-null    int64  \n",
      " 15  Flexibility                 178 non-null    int64  \n",
      " 16  timeUses_1                  178 non-null    float64\n",
      " 17  timeUses_2                  178 non-null    float64\n",
      " 18  timeUses_3                  178 non-null    float64\n",
      " 19  timeUses_4                  178 non-null    int64  \n",
      " 20  RAT_1                       178 non-null    int64  \n",
      " 21  RAT_2                       178 non-null    int64  \n",
      " 22  RAT_3                       178 non-null    int64  \n",
      " 23  RAT_4                       178 non-null    int64  \n",
      " 24  RAT_5                       178 non-null    int64  \n",
      " 25  RAT_6                       178 non-null    int64  \n",
      " 26  RAT_7                       178 non-null    int64  \n",
      " 27  RAT_8                       178 non-null    int64  \n",
      " 28  RAT_9                       178 non-null    int64  \n",
      " 29  RAT_10                      178 non-null    int64  \n",
      " 30  RAT_11                      178 non-null    int64  \n",
      " 31  RAT_12                      178 non-null    int64  \n",
      " 32  RAT_13                      178 non-null    int64  \n",
      " 33  RAT_14                      178 non-null    int64  \n",
      " 34  RAT_15                      178 non-null    int64  \n",
      " 35  RAT_16                      178 non-null    int64  \n",
      " 36  RAT_17                      178 non-null    int64  \n",
      " 37  TimeRAT_1                   178 non-null    float64\n",
      " 38  TimeRAT_2                   178 non-null    float64\n",
      " 39  TimeRAT_3                   178 non-null    float64\n",
      " 40  TimeRAT_4                   178 non-null    int64  \n",
      " 41  pos_1                       176 non-null    float64\n",
      " 42  neg_1                       176 non-null    float64\n",
      " 43  pos_2                       176 non-null    float64\n",
      " 44  neg_2                       176 non-null    float64\n",
      " 45  pos_3                       176 non-null    float64\n",
      " 46  neg_3                       176 non-null    float64\n",
      " 47  neg_4                       176 non-null    float64\n",
      " 48  neg_5                       176 non-null    float64\n",
      " 49  pos_4                       176 non-null    float64\n",
      " 50  pos_5                       176 non-null    float64\n",
      " 51  neg_6                       176 non-null    float64\n",
      " 52  pos_6                       176 non-null    float64\n",
      " 53  neg_7                       176 non-null    float64\n",
      " 54  pos_7                       176 non-null    float64\n",
      " 55  neg_8                       176 non-null    float64\n",
      " 56  pos_8                       176 non-null    float64\n",
      " 57  pos_9                       176 non-null    float64\n",
      " 58  neg_9                       176 non-null    float64\n",
      " 59  pos_10                      176 non-null    float64\n",
      " 60  neg_10                      176 non-null    float64\n",
      " 61  instr_A                     176 non-null    float64\n",
      " 62  female                      176 non-null    float64\n",
      " 63  age                         172 non-null    float64\n",
      " 64  edu                         176 non-null    float64\n",
      " 65  ethnicity_1                 3 non-null      float64\n",
      " 66  ethnicity_2                 17 non-null     float64\n",
      " 67  ethnicity_3                 15 non-null     float64\n",
      " 68  ethnicity_4                 10 non-null     float64\n",
      " 69  ethnicity_5                 2 non-null      float64\n",
      " 70  ethnicity_6                 139 non-null    float64\n",
      " 71  student                     176 non-null    float64\n",
      " 72  code                        178 non-null    int64  \n",
      " 73  care_about_rules            178 non-null    float64\n",
      " 74  pos_affect                  176 non-null    float64\n",
      " 75  neg_affect                  176 non-null    float64\n",
      " 76  RAT_perf                    178 non-null    int64  \n",
      " 77  cheated                     178 non-null    int64  \n",
      " 78  MTurkID_md5                 178 non-null    object \n",
      "dtypes: float64(40), int64(36), object(3)\n",
      "memory usage: 110.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display information about the DataFrame\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - The info() function provides a summary of the DataFrame including column names, data types, and non-null counts.\n",
    " - This helps us understand the structure of the data and identify any missing values\n",
    " - After exploring the dataset, we noticed that some columns need to be converted to the appropriate datatype for further analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Date Columns to Datetime\n",
    "Pandas allows us to convert date columns to datetime format for easier manipulation and astype(str) for converting the hash into a string (if we need that)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'StartDate' and 'EndDate' columns to datetime\n",
    "data['StartDate'] = pd.to_datetime(data['StartDate'])\n",
    "data['EndDate'] = pd.to_datetime(data['EndDate'])\n",
    "\n",
    "# Convert 'MTurkID_md5' column to string\n",
    "data['MTurkID_md5'] = data['MTurkID_md5'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speaker Notes:\n",
    "\n",
    " - We can use the pd.to_datetime() function to convert date columns to datetime format.\n",
    " - This enables us to perform datetime operations on these columns, such as filtering by date ranges.\n",
    " - We use the astype() method to convert the 'MTurkID_md5' column to a string datatype.\n",
    " - This can be useful for certain operations or when exporting the data to other formats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics\n",
    "Pandas offers a convenient way to calculate summary statistics for numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0                      StartDate  \\\n",
      "count  178.000000                            178   \n",
      "mean    89.500000  2012-11-17 23:27:10.505618176   \n",
      "min      1.000000            2012-11-17 22:49:18   \n",
      "25%     45.250000     2012-11-17 23:04:57.500000   \n",
      "50%     89.500000     2012-11-17 23:25:27.500000   \n",
      "75%    133.750000            2012-11-17 23:46:00   \n",
      "max    178.000000            2012-11-18 01:07:15   \n",
      "std     51.528309                            NaN   \n",
      "\n",
      "                             EndDate      Cum_ID  filter  filter2  \\\n",
      "count                            178  178.000000   178.0    178.0   \n",
      "mean   2012-11-17 23:42:33.724718848   92.769663     5.0      1.0   \n",
      "min              2012-11-17 22:58:53    1.000000     5.0      1.0   \n",
      "25%    2012-11-17 23:19:35.249999872   45.250000     5.0      1.0   \n",
      "50%       2012-11-17 23:40:24.500000   93.500000     5.0      1.0   \n",
      "75%              2012-11-18 00:02:42  138.750000     5.0      1.0   \n",
      "max              2012-11-18 01:17:53  192.000000     5.0      1.0   \n",
      "std                              NaN   53.876483     0.0      0.0   \n",
      "\n",
      "       CF_headsheads1tails2  num_coin_tosses  instr  \\\n",
      "count            178.000000       178.000000  178.0   \n",
      "mean               1.466292         2.691011    1.0   \n",
      "min                1.000000         1.000000    1.0   \n",
      "25%                1.000000         3.000000    1.0   \n",
      "50%                1.000000         3.000000    1.0   \n",
      "75%                2.000000         3.000000    1.0   \n",
      "max                2.000000         3.000000    1.0   \n",
      "std                0.500270         0.713096    0.0   \n",
      "\n",
      "       reported_guessed_correctly  ...  ethnicity_4  ethnicity_5  ethnicity_6  \\\n",
      "count                  178.000000  ...         10.0          2.0        139.0   \n",
      "mean                     0.241573  ...          1.0          1.0          1.0   \n",
      "min                      0.000000  ...          1.0          1.0          1.0   \n",
      "25%                      0.000000  ...          1.0          1.0          1.0   \n",
      "50%                      0.000000  ...          1.0          1.0          1.0   \n",
      "75%                      0.000000  ...          1.0          1.0          1.0   \n",
      "max                      1.000000  ...          1.0          1.0          1.0   \n",
      "std                      0.429244  ...          0.0          0.0          0.0   \n",
      "\n",
      "          student   code  care_about_rules  pos_affect  neg_affect  \\\n",
      "count  176.000000  178.0        178.000000  176.000000  176.000000   \n",
      "mean     0.335227    1.0          4.889513    2.444318    1.481818   \n",
      "min      0.000000    1.0          1.000000    1.000000    1.000000   \n",
      "25%      0.000000    1.0          3.666667    1.800000    1.075000   \n",
      "50%      0.000000    1.0          5.166667    2.300000    1.200000   \n",
      "75%      1.000000    1.0          6.333333    3.000000    1.700000   \n",
      "max      1.000000    1.0          7.000000    5.000000    4.900000   \n",
      "std      0.473417    0.0          1.587665    0.865974    0.631107   \n",
      "\n",
      "         RAT_perf     cheated  \n",
      "count  178.000000  178.000000  \n",
      "mean     8.235955    0.241573  \n",
      "min      0.000000    0.000000  \n",
      "25%      6.000000    0.000000  \n",
      "50%      8.000000    0.000000  \n",
      "75%     11.000000    0.000000  \n",
      "max     15.000000    1.000000  \n",
      "std      3.697678    0.429244  \n",
      "\n",
      "[8 rows x 78 columns]\n"
     ]
    }
   ],
   "source": [
    "# Calculate summary statistics\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speaker Notes:\n",
    "\n",
    " - The describe() function generates descriptive statistics such as count, mean, std deviation, min, and max.\n",
    " - This gives us insights into the distribution of numerical data in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
