{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Pandas Exercise\n",
    "For this exercise, you will retrace another [post of the DataColada blog](https://datacolada.org/110), that looks at [this publication](https://journals.sagepub.com/doi/abs/10.1177/0956797615575277).\n",
    "\n",
    "After being asked to express their opinion on a local campus issue at Harvard University, students were then tasked with arguing for or against their own opinion. The hypothesis was that this would increase the desire for cleaning products.\n",
    "\n",
    "### Task 1: Import Data\n",
    "- **Loading the data into pandas**. For this experiment, you will load a CSV file containing responses from the survey. This data includes demographic information and participants' ratings of cleansing products.\n",
    "- **Commands to use**: Use `pd.read_csv()` to load your dataset into a pandas DataFrame. The file is located in `exercise_data/Gino_Kouchaki_Galinsky_Study_4_Data.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Task 2: Preliminary Data Inspection\n",
    "- **Understand the structure and the problem within the dataset**: Examine the first few rows to get an idea of the available data. Additionally, assess how students have responded to the 'yearSchool' question, can you spot the anomaly (otherwise look at the blog)\n",
    "- **Commands to use**: Use `df.head()`, `df['yearSchool'].unique()`, and `df['yearSchool'].value_counts()` to display the first few rows and analyze the responses in the 'yearSchool' column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Task 3: Data Cleaning\n",
    "- **Normalize the 'yearSchool' entries**: Remove leading/trailing spaces, convert to lower case and create a binary column to flag responses that anomalously say 'Harvard'—this is suspected to be a data tampering indicator.\n",
    "- **Commands to use**: Utilize `str.strip()`, `str.lower()`, and `np.where()` to clean and categorize the 'yearSchool' data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Task 4: Descriptive Statistics\n",
    "- **Basic Statistics**: Calculate the mean and standard deviation of the ratings for cleansing products for each survey condition.\n",
    "- **Commands to use**: Apply `df.groupby()`, `df.mean()`, and `df.std()` to group the data by condition and calculate these statistics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Task 5: Visualization\n",
    "- **Plot the average ratings of cleansing products**: Distinguish between 'Harvard' and non-'Harvard' responses, to visualize potential impacts of the suspected tampered data.\n",
    "- **Commands to use**: Configure `plt.figure()`, `plt.scatter()`, `plt.title()`, `plt.xlabel()`, `plt.ylabel()`, and `plt.show()` to create a scatter plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Task 6: Statistical Testing\n",
    "- **Conduct a t-test**: To confirm the authors' hypothesis that arguing against one’s own side increases the desire for cleansing products—and to check if the 'Harvard' data points influence this result.\n",
    "- **Commands to use**: Implement `stats.ttest_ind()` to perform the independent t-tests between groups.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teaching_data_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
